{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20abd96a-4eb5-483d-b3d9-32e1c1340ece",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a593bbe1-b8a5-4a40-b46f-4ff25f132b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1e7a28-1d18-40a7-9d19-1dcdab7537ec",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d13d5928-880f-4b88-8dfa-dc791e930001",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'BATCH_SIZE': 2098,\n",
    "    'EPOCHS': 40,\n",
    "    'LEARNING_RATE': 1e-5,\n",
    "    'SEED' : 42\n",
    "}\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99aa02da-d89b-4a18-8344-261a413bac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6421efbe-70c6-4aeb-946c-be1556e7743d",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0154cbe8-5c69-4d1a-95a6-5f834fc7ab4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (10704179, 119)\n",
      "Test shape: (1527298, 118)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "all_train = pd.read_parquet(\"./train.parquet\", engine=\"pyarrow\")\n",
    "test = pd.read_parquet(\"./test.parquet\", engine=\"pyarrow\").drop(columns=['ID'])\n",
    "\n",
    "print(\"Train shape:\", all_train.shape)\n",
    "print(\"Test shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb80e25-5b02-43da-aa4f-5ca16cd7802e",
   "metadata": {},
   "source": [
    "## Data Down-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54c0b5e0-7fd7-4c4a-bc80-6a3428204784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicked == 1 데이터\n",
    "clicked_1 = all_train[all_train['clicked'] == 1]\n",
    "\n",
    "# clicked == 0 데이터에서 동일 개수x2 만큼 무작위 추출 (다운 샘플링)\n",
    "clicked_0 = all_train[all_train['clicked'] == 0].sample(n=len(clicked_1)*2, random_state=42)\n",
    "\n",
    "# 두 데이터프레임 합치기\n",
    "train = pd.concat([clicked_1, clicked_0], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "151fc664-faa0-4951-bbbb-8b92f1ee3bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (612537, 119)\n",
      "Train clicked:0: (408358, 119)\n",
      "Train clicked:1: (204179, 119)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Train clicked:0:\", train[train['clicked']==0].shape)\n",
    "print(\"Train clicked:1:\", train[train['clicked']==1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c188a0d4-f60a-422c-bb53-ae8eba8744d6",
   "metadata": {},
   "source": [
    "## Data Column Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7ecc473-4bd8-4304-9d68-a5c01f4bbe11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features: 117\n",
      "Sequence: seq\n",
      "Target: clicked\n"
     ]
    }
   ],
   "source": [
    "# Target / Sequence\n",
    "target_col = \"clicked\"\n",
    "seq_col = \"seq\"\n",
    "\n",
    "# 학습에 사용할 피처: ID/seq/target 제외, 나머지 전부\n",
    "FEATURE_EXCLUDE = {target_col, seq_col, \"ID\"}\n",
    "feature_cols = [c for c in train.columns if c not in FEATURE_EXCLUDE]\n",
    "\n",
    "print(\"Num features:\", len(feature_cols))\n",
    "print(\"Sequence:\", seq_col)\n",
    "print(\"Target:\", target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426899fa-b4f3-480d-b7de-8d7e811ad4f8",
   "metadata": {},
   "source": [
    "## Define Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3c0b13b-3a81-4a2e-a753-1f9d8aa467ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClickDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, seq_col, target_col=None, has_target=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.feature_cols = feature_cols\n",
    "        self.seq_col = seq_col\n",
    "        self.target_col = target_col\n",
    "        self.has_target = has_target\n",
    "\n",
    "        # 비-시퀀스 피처: 전부 연속값으로\n",
    "        self.X = self.df[self.feature_cols].astype(float).fillna(0).values\n",
    "\n",
    "        # 시퀀스: 문자열 그대로 보관 (lazy 파싱)\n",
    "        self.seq_strings = self.df[self.seq_col].astype(str).values\n",
    "\n",
    "        if self.has_target:\n",
    "            self.y = self.df[self.target_col].astype(np.float32).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.X[idx], dtype=torch.float)\n",
    "\n",
    "        # 전체 시퀀스 사용 (빈 시퀀스만 방어)\n",
    "        s = self.seq_strings[idx]\n",
    "        if s:\n",
    "            arr = np.fromstring(s, sep=\",\", dtype=np.float32)\n",
    "        else:\n",
    "            arr = np.array([], dtype=np.float32)\n",
    "\n",
    "        if arr.size == 0:\n",
    "            arr = np.array([0.0], dtype=np.float32)  # 빈 시퀀스 방어\n",
    "\n",
    "        seq = torch.from_numpy(arr)  # shape (seq_len,)\n",
    "\n",
    "        if self.has_target:\n",
    "            y = torch.tensor(self.y[idx], dtype=torch.float)\n",
    "            return x, seq, y\n",
    "        else:\n",
    "            return x, seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b95f1cd-e8e8-4420-ad26-c639e36e472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_train(batch):\n",
    "    xs, seqs, ys = zip(*batch)\n",
    "    xs = torch.stack(xs)\n",
    "    ys = torch.stack(ys)\n",
    "    seqs_padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True, padding_value=0.0)\n",
    "    seq_lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
    "    seq_lengths = torch.clamp(seq_lengths, min=1)  # 빈 시퀀스 방지\n",
    "    return xs, seqs_padded, seq_lengths, ys\n",
    "\n",
    "def collate_fn_infer(batch):\n",
    "    xs, seqs = zip(*batch)\n",
    "    xs = torch.stack(xs)\n",
    "    seqs_padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True, padding_value=0.0)\n",
    "    seq_lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
    "    seq_lengths = torch.clamp(seq_lengths, min=1)\n",
    "    return xs, seqs_padded, seq_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6649f6ff-cb10-45ee-b787-d2e7e652c871",
   "metadata": {},
   "source": [
    "## Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9144bc61-0942-4ed3-bb52-e347d571ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularSeqModel(nn.Module):\n",
    "    def __init__(self, d_features, lstm_hidden=32, hidden_units=[1024, 512, 256, 128], dropout=0.2):\n",
    "        super().__init__()\n",
    "        # 모든 비-시퀀스 피처에 BN\n",
    "        self.bn_x = nn.BatchNorm1d(d_features)\n",
    "        # seq: 숫자 시퀀스 → LSTM\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=lstm_hidden, batch_first=True)\n",
    "\n",
    "        # 최종 MLP\n",
    "        input_dim = d_features + lstm_hidden\n",
    "        layers = []\n",
    "        for h in hidden_units:\n",
    "            layers += [nn.Linear(input_dim, h), nn.ReLU(), nn.Dropout(dropout)]\n",
    "            input_dim = h\n",
    "        layers += [nn.Linear(input_dim, 1)]\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x_feats, x_seq, seq_lengths):\n",
    "        # 비-시퀀스 피처\n",
    "        x = self.bn_x(x_feats)\n",
    "\n",
    "        # 시퀀스 → LSTM (pack)\n",
    "        x_seq = x_seq.unsqueeze(-1)  # (B, L, 1)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            x_seq, seq_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        _, (h_n, _) = self.lstm(packed)\n",
    "        h = h_n[-1]                  # (B, lstm_hidden)\n",
    "\n",
    "        z = torch.cat([x, h], dim=1)\n",
    "        return self.mlp(z).squeeze(1)  # logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c6ad06-d840-4ac3-b565-4d2450c0af39",
   "metadata": {},
   "source": [
    "## Train / Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d94d11-f7b9-449e-b631-e70224df92c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_df, feature_cols, seq_col, target_col,\n",
    "                batch_size=512, epochs=3, lr=1e-3, device=\"cuda\"):\n",
    "\n",
    "    # 1) split\n",
    "    tr_df, va_df = train_test_split(train_df, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # 2) Dataset / Loader (l_max 인자 제거)\n",
    "    train_dataset = ClickDataset(tr_df, feature_cols, seq_col, target_col, has_target=True)\n",
    "    val_dataset   = ClickDataset(va_df, feature_cols, seq_col, target_col, has_target=True)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  collate_fn=collate_fn_train)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, collate_fn=collate_fn_train)\n",
    "\n",
    "    # 3) 모델\n",
    "    d_features = len(feature_cols)\n",
    "    model = TabularSeqModel(d_features=d_features, lstm_hidden=64, hidden_units=[256,128], dropout=0.2).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # 4) Loop\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for xs, seqs, seq_lens, ys in tqdm(train_loader, desc=f\"Train Epoch {epoch}\"):\n",
    "            xs, seqs, seq_lens, ys = xs.to(device), seqs.to(device), seq_lens.to(device), ys.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xs, seqs, seq_lens)\n",
    "            loss = criterion(logits, ys)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * ys.size(0)\n",
    "        train_loss /= len(train_dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for xs, seqs, seq_lens, ys in tqdm(val_loader, desc=f\"Val Epoch {epoch}\"):\n",
    "                xs, seqs, seq_lens, ys = xs.to(device), seqs.to(device), seq_lens.to(device), ys.to(device)\n",
    "                logits = model(xs, seqs, seq_lens)\n",
    "                loss = criterion(logits, ys)\n",
    "                val_loss += loss.item() * len(ys)\n",
    "        val_loss /= len(val_dataset)\n",
    "\n",
    "        print(f\"[Epoch {epoch}] Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0999f03-85ca-4eaf-bea0-822cda393d29",
   "metadata": {},
   "source": [
    "## Run!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b730bdf4-9697-40b1-b53b-1c10380ff43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 100%|██████████| 234/234 [01:38<00:00,  2.37it/s]\n",
      "Val Epoch 1: 100%|██████████| 59/59 [00:15<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.6694 | Val Loss: 0.6437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2: 100%|██████████| 234/234 [01:40<00:00,  2.33it/s]\n",
      "Val Epoch 2: 100%|██████████| 59/59 [00:15<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 0.6306 | Val Loss: 0.6217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3: 100%|██████████| 234/234 [01:36<00:00,  2.42it/s]\n",
      "Val Epoch 3: 100%|██████████| 59/59 [00:15<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 0.6179 | Val Loss: 0.6148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4: 100%|██████████| 234/234 [01:40<00:00,  2.33it/s]\n",
      "Val Epoch 4: 100%|██████████| 59/59 [00:16<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 0.6118 | Val Loss: 0.6093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5: 100%|██████████| 234/234 [01:40<00:00,  2.34it/s]\n",
      "Val Epoch 5: 100%|██████████| 59/59 [00:16<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 0.6065 | Val Loss: 0.6036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 6: 100%|██████████| 234/234 [01:37<00:00,  2.40it/s]\n",
      "Val Epoch 6: 100%|██████████| 59/59 [00:15<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 0.6013 | Val Loss: 0.6013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 7: 100%|██████████| 234/234 [01:40<00:00,  2.32it/s]\n",
      "Val Epoch 7: 100%|██████████| 59/59 [00:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 0.5969 | Val Loss: 0.5970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 8: 100%|██████████| 234/234 [01:41<00:00,  2.30it/s]\n",
      "Val Epoch 8: 100%|██████████| 59/59 [00:16<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 0.5931 | Val Loss: 0.5928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 9: 100%|██████████| 234/234 [01:36<00:00,  2.44it/s]\n",
      "Val Epoch 9: 100%|██████████| 59/59 [00:15<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 0.5906 | Val Loss: 0.5876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 10: 100%|██████████| 234/234 [01:36<00:00,  2.43it/s]\n",
      "Val Epoch 10: 100%|██████████| 59/59 [00:15<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 0.5885 | Val Loss: 0.5862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 11: 100%|██████████| 234/234 [01:37<00:00,  2.39it/s]\n",
      "Val Epoch 11: 100%|██████████| 59/59 [00:15<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Loss: 0.5869 | Val Loss: 0.5855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 12: 100%|██████████| 234/234 [01:39<00:00,  2.36it/s]\n",
      "Val Epoch 12: 100%|██████████| 59/59 [00:15<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Loss: 0.5857 | Val Loss: 0.5819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 13: 100%|██████████| 234/234 [01:43<00:00,  2.27it/s]\n",
      "Val Epoch 13: 100%|██████████| 59/59 [00:15<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Loss: 0.5852 | Val Loss: 0.5842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 14: 100%|██████████| 234/234 [01:38<00:00,  2.38it/s]\n",
      "Val Epoch 14: 100%|██████████| 59/59 [00:16<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Loss: 0.5839 | Val Loss: 0.5829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 15: 100%|██████████| 234/234 [01:43<00:00,  2.27it/s]\n",
      "Val Epoch 15: 100%|██████████| 59/59 [00:15<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train Loss: 0.5836 | Val Loss: 0.5813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 16: 100%|██████████| 234/234 [01:40<00:00,  2.32it/s]\n",
      "Val Epoch 16: 100%|██████████| 59/59 [00:16<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train Loss: 0.5830 | Val Loss: 0.5820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 17: 100%|██████████| 234/234 [01:40<00:00,  2.32it/s]\n",
      "Val Epoch 17: 100%|██████████| 59/59 [00:14<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train Loss: 0.5825 | Val Loss: 0.5812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 18: 100%|██████████| 234/234 [01:32<00:00,  2.52it/s]\n",
      "Val Epoch 18: 100%|██████████| 59/59 [00:15<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train Loss: 0.5818 | Val Loss: 0.5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 19: 100%|██████████| 234/234 [01:41<00:00,  2.31it/s]\n",
      "Val Epoch 19: 100%|██████████| 59/59 [00:15<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train Loss: 0.5816 | Val Loss: 0.5781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 20: 100%|██████████| 234/234 [01:44<00:00,  2.23it/s]\n",
      "Val Epoch 20: 100%|██████████| 59/59 [00:17<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Train Loss: 0.5809 | Val Loss: 0.5803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 21: 100%|██████████| 234/234 [01:43<00:00,  2.27it/s]\n",
      "Val Epoch 21: 100%|██████████| 59/59 [00:16<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] Train Loss: 0.5808 | Val Loss: 0.5787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 22: 100%|██████████| 234/234 [01:39<00:00,  2.36it/s]\n",
      "Val Epoch 22: 100%|██████████| 59/59 [00:15<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22] Train Loss: 0.5803 | Val Loss: 0.5791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 23: 100%|██████████| 234/234 [01:37<00:00,  2.40it/s]\n",
      "Val Epoch 23: 100%|██████████| 59/59 [00:15<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23] Train Loss: 0.5799 | Val Loss: 0.5779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 24: 100%|██████████| 234/234 [01:37<00:00,  2.41it/s]\n",
      "Val Epoch 24: 100%|██████████| 59/59 [00:16<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24] Train Loss: 0.5795 | Val Loss: 0.5780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 25: 100%|██████████| 234/234 [01:43<00:00,  2.27it/s]\n",
      "Val Epoch 25: 100%|██████████| 59/59 [00:15<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25] Train Loss: 0.5795 | Val Loss: 0.5804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 26: 100%|██████████| 234/234 [01:38<00:00,  2.37it/s]\n",
      "Val Epoch 26: 100%|██████████| 59/59 [00:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26] Train Loss: 0.5788 | Val Loss: 0.5772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 27: 100%|██████████| 234/234 [01:41<00:00,  2.30it/s]\n",
      "Val Epoch 27: 100%|██████████| 59/59 [00:16<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27] Train Loss: 0.5785 | Val Loss: 0.5795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 28: 100%|██████████| 234/234 [01:39<00:00,  2.36it/s]\n",
      "Val Epoch 28: 100%|██████████| 59/59 [00:15<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28] Train Loss: 0.5783 | Val Loss: 0.5797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 29: 100%|██████████| 234/234 [01:40<00:00,  2.34it/s]\n",
      "Val Epoch 29: 100%|██████████| 59/59 [00:15<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29] Train Loss: 0.5781 | Val Loss: 0.5770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 30: 100%|██████████| 234/234 [01:40<00:00,  2.33it/s]\n",
      "Val Epoch 30: 100%|██████████| 59/59 [00:15<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30] Train Loss: 0.5780 | Val Loss: 0.5767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 31: 100%|██████████| 234/234 [01:37<00:00,  2.39it/s]\n",
      "Val Epoch 31: 100%|██████████| 59/59 [00:15<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31] Train Loss: 0.5777 | Val Loss: 0.5756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 32: 100%|██████████| 234/234 [01:36<00:00,  2.43it/s]\n",
      "Val Epoch 32: 100%|██████████| 59/59 [00:15<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32] Train Loss: 0.5773 | Val Loss: 0.5745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 33: 100%|██████████| 234/234 [01:40<00:00,  2.33it/s]\n",
      "Val Epoch 33: 100%|██████████| 59/59 [00:16<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33] Train Loss: 0.5773 | Val Loss: 0.5747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 34: 100%|██████████| 234/234 [01:39<00:00,  2.36it/s]\n",
      "Val Epoch 34: 100%|██████████| 59/59 [00:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34] Train Loss: 0.5770 | Val Loss: 0.5769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 35: 100%|██████████| 234/234 [01:41<00:00,  2.30it/s]\n",
      "Val Epoch 35: 100%|██████████| 59/59 [00:15<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35] Train Loss: 0.5766 | Val Loss: 0.5756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 36: 100%|██████████| 234/234 [01:41<00:00,  2.32it/s]\n",
      "Val Epoch 36: 100%|██████████| 59/59 [00:15<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36] Train Loss: 0.5765 | Val Loss: 0.5744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 37: 100%|██████████| 234/234 [01:39<00:00,  2.36it/s]\n",
      "Val Epoch 37: 100%|██████████| 59/59 [00:15<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37] Train Loss: 0.5765 | Val Loss: 0.5743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 38: 100%|██████████| 234/234 [01:40<00:00,  2.33it/s]\n",
      "Val Epoch 38: 100%|██████████| 59/59 [00:15<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38] Train Loss: 0.5764 | Val Loss: 0.5762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 39: 100%|██████████| 234/234 [01:40<00:00,  2.34it/s]\n",
      "Val Epoch 39: 100%|██████████| 59/59 [00:15<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39] Train Loss: 0.5763 | Val Loss: 0.5744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 40: 100%|██████████| 234/234 [01:39<00:00,  2.36it/s]\n",
      "Val Epoch 40: 100%|██████████| 59/59 [00:15<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40] Train Loss: 0.5760 | Val Loss: 0.5741\n"
     ]
    }
   ],
   "source": [
    "model = train_model(\n",
    "    train_df=train,\n",
    "    feature_cols=feature_cols,\n",
    "    seq_col=seq_col,\n",
    "    target_col=target_col,\n",
    "    batch_size=CFG['BATCH_SIZE'],\n",
    "    epochs=CFG['EPOCHS'],\n",
    "    lr=CFG['LEARNING_RATE'],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5421c1-a18d-43de-934e-d0ee5af34594",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f64e9288-e35d-4e03-bb41-2c4d1fd5ccaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 728/728 [03:20<00:00,  3.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1) Dataset/Loader\n",
    "test_ds = ClickDataset(test, feature_cols, seq_col, has_target=False)\n",
    "test_ld = DataLoader(test_ds, batch_size=CFG['BATCH_SIZE'], shuffle=False, collate_fn=collate_fn_infer)\n",
    "\n",
    "# 2) Predict\n",
    "model.eval()\n",
    "outs = []\n",
    "with torch.no_grad():\n",
    "    for xs, seqs, lens in tqdm(test_ld, desc=\"Inference\"):\n",
    "        xs, seqs, lens = xs.to(device), seqs.to(device), lens.to(device)\n",
    "        outs.append(torch.sigmoid(model(xs, seqs, lens)).cpu())\n",
    "\n",
    "test_preds = torch.cat(outs).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addc0a92-05f9-4be6-9e45-cc52240afc3e",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "757f01bc-51a2-46bf-983f-a54e91abe222",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['clicked'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "289fc0a5-d97a-4cd6-abfb-245b7383ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytroch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
